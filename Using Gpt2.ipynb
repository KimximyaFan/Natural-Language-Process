{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39a38c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c779210de914a4f8ea94735b0eab8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68145887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ae72d3146c4011a9ea838a64034f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyjin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hyjin\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee2915be8ff484583de49205be5360c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d266c35c1a4f2b85cb0029bb63aeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11ff2ced4d44a94aa5ec192c20aa01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d73e08ac06a461f9e5cdaf39eb79f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyjin\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f112d74c8e2a4f99a6a401a94619f497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4a3d6ebe4e4f61b44b14aea668d305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a60c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a man who is continuously studying on NLP and Automata during 12 hours a day. He is a very good student. He is very good at reading and writing. He is very good at reading and writing. He is very good at\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "문장 주고 이어서 문장 생성하기\n",
    "\"\"\"\n",
    "\n",
    "# 입력 텍스트\n",
    "input_text = \"There was a man who is continuously studying on NLP and Automata during 12 hours\"\n",
    "\n",
    "# 텍스트 인코딩\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# 텍스트 생성\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# 결과 출력\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96524b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man walking down the street.\n",
      "\n",
      "\"I'm not going to tell you what happened, but I'm going to tell you what happened,\" he said. \"I'm not going to tell you what happened. I'm not going to tell\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "문장 주고 이어서 문장 생성하기2\n",
    "\"\"\"\n",
    "\n",
    "# 입력 텍스트\n",
    "input_text = \"a man walking down the street.\"\n",
    "\n",
    "# 텍스트 인코딩\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# 텍스트 생성\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# 결과 출력\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "012ee08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Unknown\n",
      "Sentiment: Unknown\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "Sentimental Analsys\n",
    "\"\"\"\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# 감정 분석 함수\n",
    "def analyze_sentiment(text):\n",
    "    # 감정 레이블 추가\n",
    "    prompt_text = f\"Text: {text}\\nSentiment:\"\n",
    "\n",
    "    # 텍스트 인코딩 (attention mask 포함)\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\", padding=False)\n",
    "    \n",
    "    # 텍스트 생성\n",
    "    output = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_length=50, num_return_sequences=1)\n",
    "\n",
    "    # 결과 텍스트 디코딩\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # 감정 레이블 추출\n",
    "    if \"Positive\" in generated_text:\n",
    "        sentiment = \"Positive\"\n",
    "    elif \"Negative\" in generated_text:\n",
    "        sentiment = \"Negative\"\n",
    "    else:\n",
    "        sentiment = \"Unknown\"\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "# 테스트 문장\n",
    "text = \"I love the new design of your website!\"\n",
    "text2 = \"I hate you\"\n",
    "\n",
    "# 감정 분석\n",
    "sentiment = analyze_sentiment(text)\n",
    "print(f\"Sentiment: {sentiment}\")\n",
    "sentiment = analyze_sentiment(text2)\n",
    "print(f\"Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42bf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
